{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.custom_loss import mae_wrap_angle, mse_wrap_angle\n",
    "from utils.load_data_raw import DataGenerator_raw, load_raw_ft_h5, load_raw_IDs_h5\n",
    "from utils.dataset_split import create_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure tf session\n",
    "config = tf.ConfigProto(device_count={'CPU': 2,\n",
    "                                      'GPU': 0},\n",
    "                        intra_op_parallelism_threads=6, # num of cores per socket\n",
    "                        inter_op_parallelism_threads=2,\n",
    "                        allow_soft_placement=True)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "# config as suggested here:\n",
    "# https://software.intel.com/en-us/articles/tips-to-improve-performance-for-popular-deep-learning-frameworks-on-multi-core-cpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(in_dim):\n",
    "    \"\"\"Define simple model\"\"\"\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(in_dim,)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    # show info\n",
    "    model.summary()\n",
    "    # compile model\n",
    "    model.compile(loss = mae_wrap_angle,\n",
    "                  optimizer = 'adam',\n",
    "                  metrics = [mse_wrap_angle])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training parameters\n",
    "batch_size = 1024\n",
    "num_epochs = 200\n",
    "\n",
    "# define filename of file containing dataset\n",
    "filename = '/media/feliximmohr/Storage/master_thesis/generated/database/raw/raw_nf10_mid/database_raw_nf10_scaledMM.h5'\n",
    "\n",
    "# list of substrings of parameters to select, e.g. 'NFCHOA', 'pos10', 'R006'\n",
    "valid_subset = [] #['LWFS','R006','M006','M027','R027','M013','R013']\n",
    "test_subset = ['NFCHOA_R006']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data indices and reference tables\n",
    "ID_ref, pos_table, cond_table, par = load_raw_IDs_h5(filename)\n",
    "# create test/validation/train dataset split\n",
    "partition = create_split(ID_ref,cond_table,test_subset,valid_split=0.2)\n",
    "# load feature and target data\n",
    "feature_data, target_data, _ = load_raw_ft_h5(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.fit_generator on batches of dataset\n",
    "\n",
    "# define generators\n",
    "params = {'dim': feature_data.shape[1],\n",
    "          'batch_size': batch_size,\n",
    "          'feature_data': feature_data.values,\n",
    "          'target_data' : target_data.values,\n",
    "          'shuffle': True,\n",
    "          'n_frames': par['nFrames']\n",
    "         }\n",
    "train_batch_generator = DataGenerator_raw(partition['train'], **params)\n",
    "valid_batch_generator = DataGenerator_raw(partition['validation'], **params)\n",
    "\n",
    "# create model\n",
    "model = simple_model(feature_data.shape[1])\n",
    "\n",
    "# define callbacks\n",
    "csv_logger = keras.callbacks.CSVLogger('log.csv')\n",
    "e_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', mode='min', patience=20)\n",
    "cb_list = [csv_logger, e_stop]\n",
    "\n",
    "history = model.fit_generator(generator = train_batch_generator,\n",
    "                              #steps_per_epoch = (num_train_samples) // batch_size),\n",
    "                              epochs = num_epochs,\n",
    "                              verbose = 1,\n",
    "                              validation_data = valid_batch_generator,\n",
    "                              #validation_steps = (num_valid_samples) // batch_size),\n",
    "                              callbacks = cb_list,\n",
    "                              use_multiprocessing = True,\n",
    "                              workers = 4,\n",
    "                              max_queue_size = 10\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train history\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss (mae w angle wrapping)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['mae_wrap_angle'])\n",
    "plt.plot(history.history['val_mae_wrap_angle'])\n",
    "plt.title('Model loss metric mae w angle wrapping')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "test_batch_generator = DataGenerator_raw(partition['test'], **params)\n",
    "score = model.evaluate_generator(test_batch_generator, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test mae w wrap:', score[1])\n",
    "#print('Test mae w/o wrap:', score[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history to json file\n",
    "import json\n",
    "with open('../../../models_trained/m3_history.json', 'w') as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# Save model\n",
    "model.save('../../../models_trained/m3_bs2048_adam_msaw_test-s18-s19-s20.h5')\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
