{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from utils.custom_loss import mae_wrap_angle, mse_wrap_angle\n",
    "from utils.load_data_raw import DataGenerator_raw, load_raw_all_h5\n",
    "from utils.dataset_split import *\n",
    "from utils.eval import *\n",
    "from utils.utils import get_filelist, open_json\n",
    "\n",
    "NUM_WORKER = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load filelist\n",
    "model_dir = '../data/models_trained/'\n",
    "filelist = get_filelist(model_dir)\n",
    "\n",
    "# load data\n",
    "dset_dir = '/media/feliximmohr/Storage/master_thesis/generated/database/raw/raw_nf10_mid/database_raw_nf10_scaledMM.h5'\n",
    "feat, targ, ID_ref, pos_t, cond_t, par = load_raw_all_h5(dset_dir)\n",
    "\n",
    "# load unscaled data\n",
    "dset_nsc_dir = '/media/feliximmohr/Storage/master_thesis/generated/database/raw/raw_nf10_mid/database_raw_nf10.h5'\n",
    "feat_nsc, targ_nsc, _, _, _, _ = load_raw_all_h5(dset_nsc_dir)\n",
    "\n",
    "# create parameter dicts for the test batch generators\n",
    "params = create_test_params(feat, targ, par, shuffle=False)\n",
    "params_nsc = create_test_params(feat_nsc, targ_nsc, par, shuffle=False)\n",
    "\n",
    "part = {}\n",
    "for i in range(len(cond_t)):\n",
    "    cond = cond_t.iloc[i]\n",
    "    cond_ids_test, pos_ids_test, subject_ids_test = get_subset_ids([cond[0]], cond_t)\n",
    "    part[cond[0]] = get_subset_sample_idx(ID_ref, cond_ids_test, pos_ids_test, subject_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_flist = [x for x in filelist if 'history' in x]\n",
    "pt_flist = [x for x in filelist if 'partition_test' in x]\n",
    "m_flist = [x for x in filelist if x not in h_flist+pt_flist]\n",
    "\n",
    "for i in range(len(m_flist)):\n",
    "    s = ' -' if i<10 else '-'\n",
    "    print(i, s, m_flist[i])\n",
    "    print(i, s, h_flist[i])\n",
    "    print(i, s, pt_flist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models, train history and test split IDs (partition['test'])\n",
    "\n",
    "#wraptest\n",
    "m64_mae = load_model(model_dir + m_flist[2], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h64_mae  = open_json(model_dir, h_flist[2])\n",
    "pt64_mae = open_json(model_dir, pt_flist[2])\n",
    "\n",
    "m64_maew = load_model(model_dir + m_flist[3], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h64_maew = open_json(model_dir, h_flist[3])\n",
    "pt64_maew = open_json(model_dir, pt_flist[3])\n",
    "\n",
    "m128_mae = load_model(model_dir + m_flist[5], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h128_mae  = open_json(model_dir, h_flist[5])\n",
    "pt128_mae = open_json(model_dir, pt_flist[5])\n",
    "\n",
    "m128_maew = load_model(model_dir + m_flist[10], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h128_maew = open_json(model_dir, h_flist[10])\n",
    "pt128_maew = open_json(model_dir, pt_flist[10])\n",
    "\n",
    "m256_mae = load_model(model_dir + m_flist[14], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h256_mae  = open_json(model_dir, h_flist[14])\n",
    "pt256_mae = open_json(model_dir, pt_flist[14])\n",
    "\n",
    "m256_maew = load_model(model_dir + m_flist[15], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h256_maew = open_json(model_dir, h_flist[15])\n",
    "pt256_maew = open_json(model_dir, pt_flist[15])                      \n",
    "\n",
    "#normtest\n",
    "m128_maew_nn = load_model(model_dir + m_flist[9], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h128_maew_nn = open_json(model_dir, h_flist[9])\n",
    "pt128_maew_nn = open_json(model_dir, pt_flist[9])\n",
    "\n",
    "#toptest\n",
    "m128_tt = load_model(model_dir + m_flist[6], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h128_tt = open_json(model_dir, h_flist[6])\n",
    "pt128_tt = open_json(model_dir, pt_flist[6])\n",
    "\n",
    "m128bn_bs2048_tt = load_model(model_dir + m_flist[13], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h128bn_bs2048_tt = open_json(model_dir, h_flist[13])\n",
    "pt128bn_bs2048_tt = open_json(model_dir, pt_flist[13])\n",
    "\n",
    "m128bn_bs256_tt = load_model(model_dir + m_flist[11], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h128bn_bs256_tt = open_json(model_dir, h_flist[11])\n",
    "pt128bn_bs256_tt = open_json(model_dir, pt_flist[11])\n",
    "\n",
    "m128_128_64_tt = load_model(model_dir + m_flist[4], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h128_128_64_tt = open_json(model_dir, h_flist[4])\n",
    "pt128_128_64_tt = open_json(model_dir, pt_flist[4])\n",
    "\n",
    "m512_256_tt = load_model(model_dir + m_flist[16], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h512_256_tt = open_json(model_dir, h_flist[16])\n",
    "pt512_256_tt = open_json(model_dir, pt_flist[16])\n",
    "\n",
    "m32_16_tt = load_model(model_dir + m_flist[0], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "h32_16_tt  = open_json(model_dir, h_flist[0])\n",
    "pt32_16_tt = open_json(model_dir, pt_flist[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: normalized vs. not normalized\n",
    "\n",
    "    Model 1: 128-128-1    m128_maew_wraptest   vs.  m128_maew_normtest_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 normalized: m128_maew\n",
    "tbg128_maew = model_complete_eval(m128_maew, h128_maew, pt128_maew, params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m128_maew, tbg128_maew, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model 1 not normalized: m128_maew_nn\n",
    "tbg128_maew_nn = model_complete_eval(m128_maew_nn, h128_maew_nn, pt128_maew_nn, params_nsc, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m128_maew_nn, tbg128_maew_nn, b_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: custom vs. non-custom loss function\n",
    "\n",
    "    Model 1: 64-32-1      m64_maew_wraptest   vs.  m64_mae_wraptest\n",
    "    Model 2: 128-128-1    m128_maew_wraptest  vs.  m128_mae_wraptest\n",
    "    Model 3: 256-128-1    m256_maew_wraptest  vs.  m256_mae_wraptest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model 1 custom loss: m64_maew\n",
    "tbg64_maew = model_complete_eval(m64_maew, h64_maew, pt64_maew, params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m64_maew, tbg64_maew, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 mae loss: m64_mae\n",
    "tbg64_mae = model_complete_eval(m64_mae, h64_mae, pt64_mae, params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m64_mae, tbg64_mae, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 custom loss: m128_maew\n",
    "tbg128_maew = model_complete_eval(m128_maew, h128_maew, pt128_maew, params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m128_maew, tbg128_maew, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 mae loss: m128_mae\n",
    "tbg128_mae = model_complete_eval(m128_mae, h128_mae, pt128_mae, params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m128_mae, tbg128_mae, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 custom loss: m256_maew\n",
    "tbg256_maew = model_complete_eval(m256_maew, h256_maew, pt256_maew, params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m256_maew, tbg256_maew, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 mae loss: m3_mae\n",
    "tbg256_mae = model_complete_eval(m256_mae, h256_mae, pt256_mae, params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m256_mae, tbg256_mae, b_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Model/Net Topology\n",
    "    Model 1:         128-128-1\n",
    "    Model 1 + BN :   128-BN-128-BN-1\n",
    "    Model 2:         128-128-64-1\n",
    "    Model 3:         512-256-1\n",
    "    Model 4:         32-16-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: m128_tt\n",
    "tbg128_tt = model_complete_eval(m128_tt, h128_tt, pt128_tt, params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m128_tt, tbg128_tt, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 + BN: m128bn_bs2048_tt\n",
    "tbg128bn_bs2048_tt = model_complete_eval(m128bn_bs2048_tt, h128bn_bs2048_tt, pt128bn_bs2048_tt, params, batch_size=2048, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m128bn_bs2048_tt, tbg128bn_bs2048_tt, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: m128_128_64_tt\n",
    "tbg128_128_64_tt = model_complete_eval(m128_128_64_tt, h128_128_64_tt, pt128_128_64_tt, params_nsc, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m128_128_64_tt, tbg128_128_64_tt, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: m512_256_tt\n",
    "tbg512_256_tt = model_complete_eval(m512_256_tt, h512_256_tt, pt512_256_tt, params_nsc, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m512_256_tt, tbg512_256_tt, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: m32_16_tt not normalized?\n",
    "tbg32_16_tt = model_complete_eval(m32_16_tt, h32_16_tt, pt32_16_tt, params_nsc, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "pred, y = model_pred_on_gen_batch(m32_16_tt, tbg32_16_tt, b_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: m128_tt\n",
    "mae_p, mse_p, loc_p = model_eval_pos(m128_tt, h128_tt, part['NFCHOA_R006'], params, ID_ref, batch_size=1000, workers=NUM_WORKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
