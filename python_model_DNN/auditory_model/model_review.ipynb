{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from utils.custom_loss import mae_wrap_angle, mse_wrap_angle, angle_diff_deg\n",
    "from utils.load_data_raw import DataGenerator_raw, load_raw_all_h5\n",
    "from utils.dataset_split import *\n",
    "from utils.eval import *\n",
    "from utils.utils import get_filelist, open_json\n",
    "\n",
    "NUM_WORKER = 4\n",
    "custom_obj={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load filelist\n",
    "model_dir = '../data/models_trained/'\n",
    "filelist = get_filelist(model_dir)\n",
    "\n",
    "# load data\n",
    "dset_dir = '/media/feliximmohr/Storage/master_thesis/generated/database/raw/raw_nf10_mid/database_raw_nf10_scaledMM.h5'\n",
    "feat, targ, ID_ref, pos_t, cond_t, par = load_raw_all_h5(dset_dir)\n",
    "\n",
    "# load unscaled data\n",
    "dset_nsc_dir = '/media/feliximmohr/Storage/master_thesis/generated/database/raw/raw_nf10_mid/database_raw_nf10.h5'\n",
    "feat_nsc, targ_nsc, _, _, _, _ = load_raw_all_h5(dset_nsc_dir)\n",
    "\n",
    "# create parameter dicts for the test batch generators\n",
    "params = create_test_params(feat, targ, par, shuffle=False)\n",
    "params_nsc = create_test_params(feat_nsc, targ_nsc, par, shuffle=False)\n",
    "\n",
    "cn = feat.columns.tolist()\n",
    "\n",
    "part = {}\n",
    "for i in range(len(cond_t)):\n",
    "    cond = cond_t.iloc[i]\n",
    "    cond_ids_test, pos_ids_test, subject_ids_test = get_subset_ids([cond[0]], cond_t)\n",
    "    part[cond[0]] = get_subset_sample_idx(ID_ref, cond_ids_test, pos_ids_test, subject_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract model and corresponding history and test partition filenames from filelist\n",
    "m_flist = [x for x in filelist if ('history' not in x) and ('partition_test' not in x)]\n",
    "h_flist = ['_' for x in np.zeros(len(m_flist))]\n",
    "pt_flist = ['_' for x in np.zeros(len(m_flist))]\n",
    "for file in filelist:\n",
    "        if ('history' in file):\n",
    "            name = file.replace('_history.json', '.h5')\n",
    "            h_flist[m_flist.index(name)] = file\n",
    "        if ('partition_test' in file):\n",
    "            name = file.replace('_partition_test.json', '.h5')\n",
    "            pt_flist[m_flist.index(name)] = file\n",
    "\n",
    "# seperate model list based on test type (topology/wrapping/normalization)\n",
    "m_flist_tt = [x for x in m_flist if 'toptest' in x]\n",
    "m_flist_nt = [x for x in m_flist if 'normtest' in x]\n",
    "m_flist_wt = [x for x in m_flist if 'wraptest' in x]\n",
    "\n",
    "h_flist_tt = [h_flist[m_flist.index(i)] for i in m_flist_tt]\n",
    "h_flist_nt = [h_flist[m_flist.index(i)] for i in m_flist_nt]\n",
    "h_flist_wt = [h_flist[m_flist.index(i)] for i in m_flist_wt]\n",
    "\n",
    "pt_flist_tt = [pt_flist[m_flist.index(i)] for i in m_flist_tt]\n",
    "pt_flist_nt = [pt_flist[m_flist.index(i)] for i in m_flist_nt]\n",
    "pt_flist_wt = [pt_flist[m_flist.index(i)] for i in m_flist_wt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_filelist(flist):\n",
    "    \"\"\"Print tuple of filelists incl index.\"\"\"\n",
    "    if not isinstance(flist,tuple):\n",
    "        flist = (flist,)\n",
    "        \n",
    "    for i in range(len(flist[0])):\n",
    "        s = ' -' if i<10 else '-'\n",
    "        for j in range(len(flist)):\n",
    "            print(i, s, flist[j][i])\n",
    "\n",
    "# print model list\n",
    "print_filelist(m_flist)\n",
    "#print_filelist((m_flist,h_flist,pt_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_m_h_pt(model_dir, m_flist, h_flist, pt_flist):\n",
    "    \"\"\"Load models from model list and corresponding history and test partition.\"\"\"\n",
    "    m = []\n",
    "    h = ['_' for x in np.zeros(len(m_flist))]\n",
    "    p = ['_' for x in np.zeros(len(m_flist))]\n",
    "    for i,j in enumerate(m_flist):\n",
    "        m.append(load_model(model_dir + j, custom_objects=custom_obj))\n",
    "        if h_flist[i] != '_':\n",
    "            h[i] = open_json(model_dir, h_flist[i])\n",
    "        if pt_flist[i] != '_':\n",
    "            p[i] = open_json(model_dir, pt_flist[i])\n",
    "    return m, h, p\n",
    "\n",
    "# load models\n",
    "m_nt, h_nt, pt_nt = load_m_h_pt(model_dir, m_flist_nt, h_flist_nt, pt_flist_nt)\n",
    "m_wt, h_wt, pt_wt = load_m_h_pt(model_dir, m_flist_wt, h_flist_wt, pt_flist_wt)\n",
    "m_tt, h_tt, pt_tt = load_m_h_pt(model_dir, m_flist_tt, h_flist_tt, pt_flist_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: normalized vs. not normalized\n",
    "\n",
    "    Model 1: 128-128-1    m128-128_maew_normtest_neg  vs.  m128-128_maew_normtest_sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_filelist(m_flist_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 not normalized: m128-128_maew_normtest_neg\n",
    "tbg128_maew_neg = model_complete_eval(m_nt[0], h_nt[0], pt_nt[0], params_nsc, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m_nt[0], tbg128_maew_neg, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model 1 normalized: m128-128_maew_normtest_sc\n",
    "tbg128_maew_sc = model_complete_eval(m_nt[1], h_nt[1], pt_nt[1], params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m_nt[1], tbg128_maew_sc, b_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: non-custom vs. custom loss function\n",
    "\n",
    "    Model 1: 64-32-1      m064-032_mae_wraptest  vs.  m064-032_maew_wraptest\n",
    "    Model 2: 128-128-1    m128-128_mae_wraptest  vs.  m128-128_maew_wraptest\n",
    "    Model 3: 256-128-1    m256-128_mae_wraptest  vs.  m256-128_maew_wraptest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_filelist(m_flist_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model 1 mae loss: m064-032_mae\n",
    "tbg64_maew = model_complete_eval(m_wt[0], h_wt[0], p_wt[0], params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m_wt[0], tbg64_maew, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 custom loss: m64_maew\n",
    "tbg64_mae = model_complete_eval(m_wt[1], h_wt[1], p_wt[1], params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m_wt[1], tbg64_mae, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 mae loss: m128-128_mae\n",
    "tbg128_mae = model_complete_eval(m_wt[2], h_wt[2], p_wt[2], params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m_wt[2], tbg128_mae, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 custom loss: m128-128_maew\n",
    "tbg128_maew = model_complete_eval(m_wt[3], h_wt[3], p_wt[3], params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m_wt[3], tbg128_maew, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 mae loss: m256-128_mae\n",
    "tbg256_mae = model_complete_eval(m_wt[4], h_wt[4], p_wt[4], params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m_wt[4], tbg256_mae, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 custom loss: m256-128_maew\n",
    "tbg256_maew = model_complete_eval(m_wt[5], h_wt[5], p_wt[5], params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m_wt[5], tbg256_maew, b_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Model/Net Topology\n",
    "\n",
    "    TODO\n",
    "    Model 1:         128-128-1\n",
    "    Model 1 + BN :   128-BN-128-BN-1\n",
    "    Model 2:         128-128-64-1\n",
    "    Model 3:         512-256-1\n",
    "    Model 4:         32-16-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_filelist(m_flist_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: m128_tt\n",
    "tbg128_tt = model_complete_eval(m128_tt, h128_tt, pt128_tt, params, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m128_tt, tbg128_tt, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 + BN: m128bn_bs2048_tt\n",
    "tbg128bn_bs2048_tt = model_complete_eval(m128bn_bs2048_tt, h128bn_bs2048_tt, pt128bn_bs2048_tt, params, batch_size=2048, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m128bn_bs2048_tt, tbg128bn_bs2048_tt, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: m128_128_64_tt\n",
    "tbg128_128_64_tt = model_complete_eval(m128_128_64_tt, h128_128_64_tt, pt128_128_64_tt, params_nsc, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m128_128_64_tt, tbg128_128_64_tt, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: m512_256_tt\n",
    "tbg512_256_tt = model_complete_eval(m512_256_tt, h512_256_tt, pt512_256_tt, params_nsc, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "#pred, y = model_pred_on_gen_batch(m512_256_tt, tbg512_256_tt, b_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: m32_16_tt not normalized?\n",
    "tbg32_16_tt = model_complete_eval(m32_16_tt, h32_16_tt, pt32_16_tt, params_nsc, batch_size=1024, workers=NUM_WORKER)\n",
    "\n",
    "#predict on model\n",
    "pred, y = model_pred_on_gen_batch(m32_16_tt, tbg32_16_tt, b_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: m128_tt\n",
    "mae_p, mse_p, loc_p = model_eval_pos(m128_tt, h128_tt, part['NFCHOA_R006'], params, ID_ref, batch_size=1000, workers=NUM_WORKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get IDs of subset of data per position of one condition\n",
    "part_x_M027, pos_ids = get_pos_IDs(part['NFCHOA_M027'],ID_ref)\n",
    "part_x_R006, _ = get_pos_IDs(part['NFCHOA_R006'],ID_ref)\n",
    "\n",
    "params_t = params.copy()\n",
    "params_t['batch_size'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MSE = squared bias + variance\n",
    "n_model = len(m_flist_tt)\n",
    "MSE_R006 = np.zeros(n_model)\n",
    "tau_sq_R006 = np.zeros(n_model)\n",
    "sigma_sq_R006 = np.zeros(n_model)\n",
    "MSE_M027 = np.zeros(n_model)\n",
    "tau_sq_M027 = np.zeros(n_model)\n",
    "sigma_sq_M027 = np.zeros(n_model)\n",
    "\n",
    "for i in np.arange(n_model):\n",
    "    model = load_model(model_dir + m_flist_tt[i], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "    MSE_R006[i], tau_sq_R006[i], sigma_sq_R006[i], _, _ = calc_errors_m(model, part_x_R006, params_t, pos_ids, verbose=0, workers=NUM_WORKER)\n",
    "    MSE_M027[i], tau_sq_M027[i], sigma_sq_M027[i], _, _ = calc_errors_m(model, part_x_M027, params_t, pos_ids, verbose=0, workers=NUM_WORKER)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_nlist = []\n",
    "loss_f = []\n",
    "model_str = []\n",
    "test_dset = []\n",
    "bs = []\n",
    "for i in np.arange(n_model):\n",
    "    strn = m_flist[i].split('_')\n",
    "    loss_f.append('{:<5}'.format(strn[1]))\n",
    "    model_str.append('{:<15}'.format(strn[0]))\n",
    "    test_dset.append('{:<15}'.format(strn[4]))\n",
    "    bs.append('{:<5}'.format(strn[3]))\n",
    "    m_nlist.append(strn[0]+'_'+strn[1]+'_'+strn[4])\n",
    "\n",
    "data = {\n",
    "    'model':model_str,\n",
    "    'loss_f':loss_f,\n",
    "    'test_dset':test_dset,\n",
    "    'bs':bs,\n",
    "    'MSE_R006' : MSE_R006,\n",
    "    'sq_bias_R006': tau_sq_R006,\n",
    "    'variance_R006': sigma_sq_R006,\n",
    "    'MSE_M027': MSE_M027,\n",
    "    'sq_bias_M027': tau_sq_M027,\n",
    "    'variance_M027': sigma_sq_M027    \n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
