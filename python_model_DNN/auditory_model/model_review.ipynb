{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import walk\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "\n",
    "from utils.custom_loss import mae_wrap_angle, mse_wrap_angle\n",
    "from utils.load_data_raw import DataGenerator_raw, load_raw_all_h5\n",
    "from utils.dataset_split import create_split\n",
    "\n",
    "NUM_WORKER = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(hist, val_hist, metric_str):\n",
    "    \"\"\"Plot train history.\"\"\"\n",
    "    plt.plot(hist)\n",
    "    plt.plot(val_hist)\n",
    "    plt.title('Model loss ('+metric_str+')')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def model_eval(model, history, part_test=[], batch_size=1024, feature_data=[], target_data=[], par=[]):\n",
    "    \"\"\"Evaluate a specified model. Show model topology, training history and loss on test data set.\"\"\"\n",
    "    # Get metrics from history dict\n",
    "    metrics = list(history.keys())\n",
    "    v_met = [x for x in metrics if 'val' in x]\n",
    "    n = len(v_met)\n",
    "    metrics = metrics[n:]\n",
    "    \n",
    "    # Show model/net topology\n",
    "    model.summary()\n",
    "\n",
    "    # Evaluate model\n",
    "    if part_test:\n",
    "        params = {'dim': feature_data.shape[1],\n",
    "          'batch_size': batch_size,\n",
    "          'feature_data': feature_data.values,\n",
    "          'target_data' : target_data.values,\n",
    "          'shuffle': False,\n",
    "          'n_frames': par['nFrames'],\n",
    "          'n_angles': par['nAngles']\n",
    "         }\n",
    "        print('Model Evaluation:')\n",
    "        test_batch_generator = DataGenerator_raw(part_test, **params)\n",
    "        score = model.evaluate_generator(test_batch_generator, verbose=1, use_multiprocessing=True, workers=NUM_WORKER)\n",
    "        for i, m in enumerate(metrics):\n",
    "            print('Test '+m+':', score[i])\n",
    "    else:\n",
    "        test_batch_generator = 0\n",
    "\n",
    "    # Plot train history\n",
    "    for j in range(n):\n",
    "        plot_history(history[metrics[j]], history[v_met[j]], metrics[j])\n",
    "        \n",
    "    return test_batch_generator\n",
    "\n",
    "def open_json(dir, filename):\n",
    "    \"\"\"Open json file abd return its contents.\"\"\"\n",
    "    with open(dir + filename) as json_file:\n",
    "        content = json.load(json_file)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../data/models_trained/'\n",
    "# load filelist\n",
    "filelist = []\n",
    "for (dirpath, dirnames, filenames) in walk(model_dir):\n",
    "    filelist.extend(filenames)\n",
    "filelist.sort()\n",
    "\n",
    "dset_dir = '/media/feliximmohr/Storage/master_thesis/generated/database/raw/raw_nf10_mid/database_raw_nf10_scaledMM.h5'\n",
    "feat, targ, _, _, _, par = load_raw_all_h5(dset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  - m064_maew_adam_bs1024_t-split_wraptest.h5\n",
      "0  - m064_maew_adam_bs1024_t-split_wraptest_history.json\n",
      "0  - m064_maew_adam_bs1024_t-split_wraptest_partition_test.json\n",
      "1  - m128_mae_adam_bs1024_t-split_wraptest.h5\n",
      "1  - m128_mae_adam_bs1024_t-split_wraptest_history.json\n",
      "1  - m128_mae_adam_bs1024_t-split_wraptest_partition_test.json\n",
      "2  - m128_maew_adam_bs1024_t-NHR006_toptest.h5\n",
      "2  - m128_maew_adam_bs1024_t-NHR006_toptest_history.json\n",
      "2  - m128_maew_adam_bs1024_t-NHR006_toptest_partition_test.json\n",
      "3  - m128_maew_adam_bs1024_t-split_wraptest.h5\n",
      "3  - m128_maew_adam_bs1024_t-split_wraptest_history.json\n",
      "3  - m128_maew_adam_bs1024_t-split_wraptest_partition_test.json\n",
      "4  - m256_mae_adam_bs1024_t-split_wraptest.h5\n",
      "4  - m256_mae_adam_bs1024_t-split_wraptest_history.json\n",
      "4  - m256_mae_adam_bs1024_t-split_wraptest_partition_test.json\n",
      "5  - m256_maew_adam_bs1024_t-split_wraptest.h5\n",
      "5  - m256_maew_adam_bs1024_t-split_wraptest_history.json\n",
      "5  - m256_maew_adam_bs1024_t-split_wraptest_partition_test.json\n"
     ]
    }
   ],
   "source": [
    "h_flist = [x for x in filelist if 'history' in x]\n",
    "pt_flist = [x for x in filelist if 'partition_test' in x]\n",
    "m_flist = [x for x in filelist if x not in h_flist+pt_flist]\n",
    "\n",
    "for i in range(len(m_flist)):\n",
    "    s = ' -' if i<10 else '-'\n",
    "    print(i, s, m_flist[i])\n",
    "    print(i, s, h_flist[i])\n",
    "    print(i, s, pt_flist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1006 21:49:48.197153 139894133552960 deprecation_wrapper.py:119] From /home/feliximmohr/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1006 21:49:48.225629 139894133552960 deprecation_wrapper.py:119] From /home/feliximmohr/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1006 21:49:48.299826 139894133552960 deprecation_wrapper.py:119] From /home/feliximmohr/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1006 21:49:48.301239 139894133552960 deprecation_wrapper.py:119] From /home/feliximmohr/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1006 21:49:48.302207 139894133552960 deprecation_wrapper.py:119] From /home/feliximmohr/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1006 21:49:48.433130 139894133552960 deprecation_wrapper.py:119] From /home/feliximmohr/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load models, train history and test split IDs (partition['test'])\n",
    "#m1_mae = load_model(model_dir + m_flist[0], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "m1_maew = load_model(model_dir + m_flist[0], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "m2_mae = load_model(model_dir + m_flist[1], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "m2_maew = load_model(model_dir + m_flist[3], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "m3_mae = load_model(model_dir + m_flist[4], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "m3_maew = load_model(model_dir + m_flist[5], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "\n",
    "\n",
    "m1_tt = load_model(model_dir + m_flist[2], custom_objects={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle})\n",
    "\n",
    "#h1_mae  = open_json(model_dir, h_flist[0])\n",
    "h1_maew = open_json(model_dir, h_flist[0])\n",
    "h2_mae  = open_json(model_dir, h_flist[1])\n",
    "h2_maew = open_json(model_dir, h_flist[3])\n",
    "h3_mae  = open_json(model_dir, h_flist[4])\n",
    "h3_maew = open_json(model_dir, h_flist[5])\n",
    "\n",
    "h1_tt = open_json(model_dir, h_flist[2])\n",
    "\n",
    "\n",
    "#pt1_mae = open_json(model_dir, pt_flist[0])\n",
    "pt1_maew = open_json(model_dir, pt_flist[0])\n",
    "pt2_mae = open_json(model_dir, pt_flist[1])\n",
    "pt2_maew = open_json(model_dir, pt_flist[3])\n",
    "pt3_mae = open_json(model_dir, pt_flist[4])\n",
    "pt3_maew = open_json(model_dir, pt_flist[5])\n",
    "\n",
    "pt1_tt = open_json(model_dir, pt_flist[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: custom vs. non-custom loss function\n",
    "\n",
    "    Model 1: 64-32-1      m64_maew_wraptest   vs.  m64_mae_wraptest\n",
    "    Model 2: 128-128-1    m128_maew_wraptest  vs.  m128_mae_wraptest\n",
    "    Model 3: 256-128-1    m256_maew_wraptest  vs.  m256_mae_wraptest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model 1 custom loss: m1_maew\n",
    "tb_gen1_maew = model_eval(m1_maew, h1_maew, pt1_maew, batch_size=1024, feature_data=feat, target_data=targ, par=par)\n",
    "\n",
    "#predict on model\n",
    "#X,y = tb_gen1_maew.__getitem__(123)\n",
    "#pred = m1_maew.predict_on_batch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 mae loss: m1_mae\n",
    "tb_gen1_mae = model_eval(m1_mae, h1_mae, pt1_mae, batch_size=1024, feature_data=feat, target_data=targ, par=par)\n",
    "\n",
    "#predict on model\n",
    "#X,y = tb_gen1_mae.__getitem__(123)\n",
    "#pred = m1_mae.predict_on_batch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 custom loss: m2_maew\n",
    "tb_gen2_maew = model_eval(m2_maew, h2_maew, pt2_maew, batch_size=1024, feature_data=feat, target_data=targ, par=par)\n",
    "\n",
    "#predict on model\n",
    "#X,y = tb_gen2_maew.__getitem__(123)\n",
    "#pred = m2_maew.predict_on_batch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 mae loss: m2_mae\n",
    "tb_gen2_mae = model_eval(m2_mae, h2_mae, pt2_mae, batch_size=1024, feature_data=feat, target_data=targ, par=par)\n",
    "\n",
    "#predict on model\n",
    "#X,y = tb_gen2_mae.__getitem__(123)\n",
    "#pred = m2_mae.predict_on_batch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 custom loss: m3_maew\n",
    "tb_gen3_maew = model_eval(m3_maew, h3_maew, pt3_maew, batch_size=1024, feature_data=feat, target_data=targ, par=par)\n",
    "\n",
    "#predict on model\n",
    "#X,y = tb_gen3_maew.__getitem__(123)\n",
    "#pred = m3_maew.predict_on_batch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 mae loss: m3_mae\n",
    "tb_gen3_mae = model_eval(m3_mae, h3_mae, pt3_mae, batch_size=1024, feature_data=feat, target_data=targ, par=par)\n",
    "\n",
    "#predict on model\n",
    "#X,y = tb_gen3_mae.__getitem__(123)\n",
    "#pred = m3_mae.predict_on_batch(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Model/Net Topology\n",
    "    Model 1:         128-128-1\n",
    "    Model 1 + BN :   128-BN-128-BN-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: m1_tt\n",
    "tb_gen1_tt = model_eval(m1_tt, h1_tt, pt1_tt, batch_size=1024, feature_data=feat, target_data=targ, par=par)\n",
    "\n",
    "#predict on model\n",
    "#X,y = tb_gen1_tt.__getitem__(123)\n",
    "#pred = m1_tt.predict_on_batch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
