{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from utils.custom_loss import mae_wrap_angle, mse_wrap_angle, angle_diff_deg\n",
    "from utils.load_data_raw import DataGenerator_raw, load_raw_all_h5\n",
    "from utils.dataset_split import *\n",
    "from utils.eval import *\n",
    "from utils.plot import *\n",
    "from utils.utils import get_filelist, open_json\n",
    "\n",
    "NUM_WORKER = 4\n",
    "custom_obj={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load filelist\n",
    "model_dir = '../data/models_trained/'\n",
    "filelist = get_filelist(model_dir)\n",
    "\n",
    "# load data\n",
    "dset_dir = '/media/feliximmohr/Storage/master_thesis/generated/database/raw/raw_nf10_mid/database_raw_nf10_scaledMM.h5'\n",
    "feat, targ, ID_ref, pos_t, cond_t, par = load_raw_all_h5(dset_dir)\n",
    "\n",
    "# load unscaled data\n",
    "dset_nsc_dir = '/media/feliximmohr/Storage/master_thesis/generated/database/raw/raw_nf10_mid/database_raw_nf10.h5'\n",
    "feat_nsc, targ_nsc, _, _, _, _ = load_raw_all_h5(dset_nsc_dir)\n",
    "\n",
    "# create parameter dicts for the test batch generators\n",
    "params = create_test_params(feat, targ, par, shuffle=False)\n",
    "params_nsc = create_test_params(feat_nsc, targ_nsc, par, shuffle=False)\n",
    "\n",
    "cn = feat.columns.tolist()\n",
    "\n",
    "part = {}\n",
    "for i in range(len(cond_t)):\n",
    "    cond = cond_t.iloc[i]\n",
    "    cond_ids_test, pos_ids_test, subject_ids_test = get_subset_ids([cond[0]], cond_t)\n",
    "    part[cond[0]] = get_subset_sample_idx(ID_ref, cond_ids_test, pos_ids_test, subject_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract model and corresponding history and test partition filenames from filelist\n",
    "m_flist = [x for x in filelist if ('history' not in x) and ('partition_test' not in x)]\n",
    "h_flist = ['_' for x in np.zeros(len(m_flist))]\n",
    "pt_flist = ['_' for x in np.zeros(len(m_flist))]\n",
    "for file in filelist:\n",
    "        if ('history' in file):\n",
    "            name = file.replace('_history.json', '.h5')\n",
    "            h_flist[m_flist.index(name)] = file\n",
    "        if ('partition_test' in file):\n",
    "            name = file.replace('_partition_test.json', '.h5')\n",
    "            pt_flist[m_flist.index(name)] = file\n",
    "\n",
    "# seperate model list based on test type (topology/wrapping/normalization)\n",
    "m_flist_tt = [x for x in m_flist if 'toptest' in x]\n",
    "m_flist_nt = [x for x in m_flist if 'normtest' in x]\n",
    "m_flist_wt = [x for x in m_flist if 'wraptest' in x]\n",
    "\n",
    "h_flist_tt = [h_flist[m_flist.index(i)] for i in m_flist_tt]\n",
    "h_flist_nt = [h_flist[m_flist.index(i)] for i in m_flist_nt]\n",
    "h_flist_wt = [h_flist[m_flist.index(i)] for i in m_flist_wt]\n",
    "\n",
    "pt_flist_tt = [pt_flist[m_flist.index(i)] for i in m_flist_tt]\n",
    "pt_flist_nt = [pt_flist[m_flist.index(i)] for i in m_flist_nt]\n",
    "pt_flist_wt = [pt_flist[m_flist.index(i)] for i in m_flist_wt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_filelist(flist):\n",
    "    \"\"\"Print tuple of filelists incl index.\"\"\"\n",
    "    if not isinstance(flist,tuple):\n",
    "        flist = (flist,)\n",
    "        \n",
    "    for i in range(len(flist[0])):\n",
    "        s = ' -' if i<10 else '-'\n",
    "        for j in range(len(flist)):\n",
    "            print(i, s, flist[j][i])\n",
    "\n",
    "# print model list\n",
    "#print_filelist((m_flist,h_flist,pt_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_m_h_pt(model_dir, m_flist, h_flist, pt_flist):\n",
    "    \"\"\"Load models from model list and corresponding history and test partition.\"\"\"\n",
    "    m = []\n",
    "    h = ['_' for x in np.zeros(len(m_flist))]\n",
    "    p = ['_' for x in np.zeros(len(m_flist))]\n",
    "    for i,j in enumerate(m_flist):\n",
    "        m.append(load_model(model_dir + j, custom_objects=custom_obj))\n",
    "        if h_flist[i] != '_':\n",
    "            h[i] = open_json(model_dir, h_flist[i])\n",
    "        if pt_flist[i] != '_':\n",
    "            p[i] = open_json(model_dir, pt_flist[i])\n",
    "    return m, h, p\n",
    "\n",
    "# load models\n",
    "#m_nt, h_nt, pt_nt = load_m_h_pt(model_dir, m_flist_nt, h_flist_nt, pt_flist_nt)\n",
    "#m_wt, h_wt, pt_wt = load_m_h_pt(model_dir, m_flist_wt, h_flist_wt, pt_flist_wt)\n",
    "m_tt, _, _ = load_m_h_pt(model_dir, m_flist_tt, h_flist_tt, pt_flist_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_filelist(m_flist_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part_x_M027, pos_ids = get_pos_IDs(part['NFCHOA_M027'],ID_ref)\n",
    "#part_x_R006, _ = get_pos_IDs(part['NFCHOA_R006'],ID_ref)\n",
    "\n",
    "params_t = params.copy()\n",
    "params_t['batch_size'] = 1000\n",
    "\n",
    "params_t_nsc = params_nsc.copy()\n",
    "params_t_nsc['batch_size'] = 1000\n",
    "\n",
    "params_t_nic = create_test_params(feat[cn[:64]], targ, par, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred_pos(model, part, params, ID_ref):\n",
    "    \"\"\"Returns list of ndarrays of predictions on model based on test partition per position.\"\"\"\n",
    "    part_x, pos_ids = get_pos_IDs(part,ID_ref)\n",
    "    b_gen = []\n",
    "    pred = []\n",
    "    y = []\n",
    "    for j in range(len(part_x)):\n",
    "        b_gen.append(DataGenerator_raw(part_x[j], **params))\n",
    "        pred.append(model.predict_generator(b_gen[j], verbose=0, use_multiprocessing=True, workers=4))\n",
    "        y.append(get_y_gen(b_gen[j]))\n",
    "    return pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_R006 = {}\n",
    "pred_M027 = {}\n",
    "y_R006 = {}\n",
    "y_M027 = {}\n",
    "for i,md in enumerate(m_flist_tt):\n",
    "    if 'no-ic' in md:\n",
    "        params_tmp = params_t_nic\n",
    "    elif 'nsc' in md:\n",
    "        params_tmp = params_t_nsc\n",
    "    else:\n",
    "        params_tmp = params_t    \n",
    "    \n",
    "    pred_R006[md], y_R006[md] = model_pred_pos(m_tt[i] , part['NFCHOA_R006'], params_tmp, ID_ref)\n",
    "    pred_M027[md], y_M027[md] = model_pred_pos(m_tt[i] , part['NFCHOA_M027'], params_tmp, ID_ref)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(pred_M027.keys())\n",
    "k[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plots\n",
    "\n",
    "# all positions overview\n",
    "for name in k[19:]:\n",
    "    model_name, loss_name, tdata, special, bs, _ = get_model_info(name)\n",
    "    #plot_locaz_all(pred_R006[name],\n",
    "    #               l=True,\n",
    "    #               title='Model: {}{} | Loss: {} | Test-Data: {}'.format(model_name, special, loss_name, 'NFCHOA_R006'))\n",
    "    plot_locaz_all(pred_M027[name],\n",
    "                   l=True,\n",
    "                   title='Model: {}{} | Loss: {} | Test-Data: {}'.format(model_name, special, loss_name, 'NFCHOA_M027'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# individual positions incl. gt comparison\n",
    "%matplotlib\n",
    "\n",
    "m_idx = 8\n",
    "pos_idx = 0\n",
    "\n",
    "title = 'Model: {}{} | Loss: {} | Test-Data: {}\\n Position: {}'.format(model_name, special, loss_name, 'NFCHOA_M027', pos_idx)\n",
    "f, ax_p, ax_y = plot_locaz(pred_M027[k[m_idx]][pos_idx], y_M027[k[m_idx]][pos_idx], l=True)\n",
    "f.suptitle(title, fontsize='x-large')\n",
    "lines = (ax_p.get_children()[:1][0],ax_y.get_children()[:1][0],ax_p.get_children()[:][1],ax_p.get_children()[:][2],ax_p.get_children()[:][4])\n",
    "f.legend(lines, ('predictions', 'human / gt', 'mean over subjects/repititions at 0° head rotation', '± 180°','± 180°'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpart_x, tpos_ids = get_pos_IDs(part['NFCHOA_M027'],ID_ref)\n",
    "t_gen = DataGenerator_raw(tpart_x[3], **params_t)\n",
    "tX,ty = t_gen.__getitem__(33)\n",
    "\n",
    "test = y_M027[k[9]][9][36000-3000:36000-2000]\n",
    "tpred = pred_M027[k[9]][9][36000-3000:36000-2000]\n",
    "\n",
    "ty_m = np.zeros(5)\n",
    "for i in range(5):\n",
    "    ty_m[i] = np.mean(ty[i*200:i*200+200])\n",
    "    \n",
    "i = 0\n",
    "ty[i*200:i*200+200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tttt = pred_M027[k[6]][3][37800:38000]\n",
    "ttty = y_M027[k[6]][3][37800:38000]\n",
    "\n",
    "tX,ty = t_gen.__getitem__(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tX[:,:], aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "plot_partial_dependence(m_tt[9], ttX, np.arange(64), feature_names=cn,\n",
    "                        n_jobs=1, grid_resolution=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpp, tyy = model_pred_pos(m_tt[5] , part['NFCHOA_R006'], params_t_nsc, ID_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_locaz(tpp[5], tyy[5], l=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset = ['NFCHOA_R300']\n",
    "partition = create_split(ID_ref,cond_t,test_subset=test_subset,valid_split=0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': feat.shape[1],\n",
    "          'batch_size': 1000,\n",
    "          'feature_data': feat.values,\n",
    "          'target_data' : targ.values,\n",
    "          'shuffle': True,\n",
    "          'n_frames': par['nFrames'].values,\n",
    "          'n_angles': par['nAngles'].values\n",
    "         }\n",
    "train_batch_generator = DataGenerator_raw(partition['test'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = partition['test'].shape[0]\n",
    "ttX = np.zeros((tn,96))\n",
    "tty = np.zeros(tn)\n",
    "for i in range(int(tn/1000)):\n",
    "    ttX[i*1000:i*1000+1000,:],tty[i*1000:i*1000+1000] = train_batch_generator.__getitem__(i)\n",
    "    if i==round(float(i) / 100) * 100:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cn = feat.columns.tolist()\n",
    "data = {}\n",
    "for i,n in enumerate(cn):\n",
    "    data[n] = ttX[:,i]\n",
    "    data['y'] = tty\n",
    "df = pd.DataFrame(data)\n",
    "df_t = pd.DataFrame({'targets':tty})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib\n",
    "corrmat = df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(df[top_corr_features].corr(),annot=False,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp\n",
    "\n",
    "%matplotlib\n",
    "\n",
    "t_data = df\n",
    "t_target = df_t['targets']\n",
    "t_model = m_tt[9]\n",
    "\n",
    "pdp_feat = []\n",
    "for i in range(len(cn)):\n",
    "    pdp_feat.append(pdp.pdp_isolate(model=t_model,dataset=t_data,model_features=cn,feature=cn[i]))\n",
    "    print('Feature No.:')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycebox.ice import ice, ice_plot\n",
    "\n",
    "ice_df = ice(df, cn[0], m_tt[7].predict, num_grid_points=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "fig, axes = pdp.pdp_plot(pdp_isolate_out=pdp_feat[i], feature_name=cn[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
