{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from utils.custom_loss import mae_wrap_angle, mse_wrap_angle, angle_diff_deg\n",
    "from utils.load_data_raw import DataGenerator_raw, load_raw_all_h5\n",
    "from utils.dataset_split import *\n",
    "from utils.eval import *\n",
    "from utils.plot import *\n",
    "from utils.utils import get_filelist, open_json\n",
    "\n",
    "NUM_WORKER = 4\n",
    "custom_obj={'mse_wrap_angle': mse_wrap_angle, 'mae_wrap_angle': mae_wrap_angle}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load filelist\n",
    "model_dir = '../data/models_trained/'\n",
    "filelist = get_filelist(model_dir)\n",
    "\n",
    "# load data\n",
    "dset_dir = '/media/feliximmohr/Storage/master_thesis/generated/database/raw/raw_nf10_mid/database_raw_nf10_scaledMM.h5'\n",
    "feat, targ, ID_ref, pos_t, cond_t, par = load_raw_all_h5(dset_dir)\n",
    "\n",
    "# load unscaled data\n",
    "dset_nsc_dir = '/media/feliximmohr/Storage/master_thesis/generated/database/raw/raw_nf10_mid/database_raw_nf10.h5'\n",
    "feat_nsc, targ_nsc, _, _, _, _ = load_raw_all_h5(dset_nsc_dir)\n",
    "\n",
    "# create parameter dicts for the test batch generators\n",
    "params = create_test_params(feat, targ, par, shuffle=False)\n",
    "params_nsc = create_test_params(feat_nsc, targ_nsc, par, shuffle=False)\n",
    "\n",
    "cn = feat.columns.tolist()\n",
    "\n",
    "part = {}\n",
    "for i in range(len(cond_t)):\n",
    "    cond = cond_t.iloc[i]\n",
    "    cond_ids_test, pos_ids_test, subject_ids_test = get_subset_ids([cond[0]], cond_t)\n",
    "    part[cond[0]] = get_subset_sample_idx(ID_ref, cond_ids_test, pos_ids_test, subject_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract model and corresponding history and test partition filenames from filelist\n",
    "m_flist = [x for x in filelist if ('history' not in x) and ('partition_test' not in x)]\n",
    "h_flist = ['_' for x in np.zeros(len(m_flist))]\n",
    "pt_flist = ['_' for x in np.zeros(len(m_flist))]\n",
    "for file in filelist:\n",
    "        if ('history' in file):\n",
    "            name = file.replace('_history.json', '.h5')\n",
    "            h_flist[m_flist.index(name)] = file\n",
    "        if ('partition_test' in file):\n",
    "            name = file.replace('_partition_test.json', '.h5')\n",
    "            pt_flist[m_flist.index(name)] = file\n",
    "\n",
    "# seperate model list based on test type (topology/wrapping/normalization)\n",
    "m_flist_tt = [x for x in m_flist if 'toptest' in x]\n",
    "m_flist_nt = [x for x in m_flist if 'normtest' in x]\n",
    "m_flist_wt = [x for x in m_flist if 'wraptest' in x]\n",
    "\n",
    "h_flist_tt = [h_flist[m_flist.index(i)] for i in m_flist_tt]\n",
    "h_flist_nt = [h_flist[m_flist.index(i)] for i in m_flist_nt]\n",
    "h_flist_wt = [h_flist[m_flist.index(i)] for i in m_flist_wt]\n",
    "\n",
    "pt_flist_tt = [pt_flist[m_flist.index(i)] for i in m_flist_tt]\n",
    "pt_flist_nt = [pt_flist[m_flist.index(i)] for i in m_flist_nt]\n",
    "pt_flist_wt = [pt_flist[m_flist.index(i)] for i in m_flist_wt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_filelist(flist):\n",
    "    \"\"\"Print tuple of filelists incl index.\"\"\"\n",
    "    if not isinstance(flist,tuple):\n",
    "        flist = (flist,)\n",
    "        \n",
    "    for i in range(len(flist[0])):\n",
    "        s = ' -' if i<10 else '-'\n",
    "        for j in range(len(flist)):\n",
    "            print(i, s, flist[j][i])\n",
    "\n",
    "# print model list\n",
    "#print_filelist((m_flist,h_flist,pt_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_m_h_pt(model_dir, m_flist, h_flist, pt_flist):\n",
    "    \"\"\"Load models from model list and corresponding history and test partition.\"\"\"\n",
    "    m = []\n",
    "    h = ['_' for x in np.zeros(len(m_flist))]\n",
    "    p = ['_' for x in np.zeros(len(m_flist))]\n",
    "    for i,j in enumerate(m_flist):\n",
    "        m.append(load_model(model_dir + j, custom_objects=custom_obj))\n",
    "        if h_flist[i] != '_':\n",
    "            h[i] = open_json(model_dir, h_flist[i])\n",
    "        if pt_flist[i] != '_':\n",
    "            p[i] = open_json(model_dir, pt_flist[i])\n",
    "    return m, h, p\n",
    "\n",
    "# load models\n",
    "#m_nt, h_nt, pt_nt = load_m_h_pt(model_dir, m_flist_nt, h_flist_nt, pt_flist_nt)\n",
    "#m_wt, h_wt, pt_wt = load_m_h_pt(model_dir, m_flist_wt, h_flist_wt, pt_flist_wt)\n",
    "m_tt, _, _ = load_m_h_pt(model_dir, m_flist_tt, h_flist_tt, pt_flist_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Evaluation\n",
    "\n",
    "##### Print model names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_filelist(m_flist_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict on models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part_x_M027, pos_ids = get_pos_IDs(part['NFCHOA_M027'],ID_ref)\n",
    "#part_x_R006, _ = get_pos_IDs(part['NFCHOA_R006'],ID_ref)\n",
    "\n",
    "params_t = params.copy()\n",
    "params_t['batch_size'] = 1000\n",
    "\n",
    "params_t_nsc = params_nsc.copy()\n",
    "params_t_nsc['batch_size'] = 1000\n",
    "\n",
    "params_t_nic = create_test_params(feat[cn[:64]], targ, par, batch_size=1000, shuffle=False)\n",
    "\n",
    "def model_pred_pos(model, part, params, ID_ref):\n",
    "    \"\"\"Returns list of ndarrays of predictions on model based on test partition per position.\"\"\"\n",
    "    part_x, pos_ids = get_pos_IDs(part,ID_ref)\n",
    "    b_gen = []\n",
    "    pred = []\n",
    "    y = []\n",
    "    for j in range(len(part_x)):\n",
    "        b_gen.append(DataGenerator_raw(part_x[j], **params))\n",
    "        pred.append(model.predict_generator(b_gen[j], verbose=0, use_multiprocessing=True, workers=4))\n",
    "        y.append(get_y_gen(b_gen[j]))\n",
    "    return pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_R006 = {}\n",
    "pred_M027 = {}\n",
    "y_R006 = {}\n",
    "y_M027 = {}\n",
    "for i,md in enumerate(m_flist_tt):\n",
    "    if 'no-ic' in md:\n",
    "        params_tmp = params_t_nic\n",
    "    elif 'nsc' in md:\n",
    "        params_tmp = params_t_nsc\n",
    "    else:\n",
    "        params_tmp = params_t    \n",
    "    \n",
    "    pred_R006[md], y_R006[md] = model_pred_pos(m_tt[i] , part['NFCHOA_R006'], params_tmp, ID_ref)\n",
    "    pred_M027[md], y_M027[md] = model_pred_pos(m_tt[i] , part['NFCHOA_M027'], params_tmp, ID_ref)\n",
    "    #print(i)\n",
    "k = list(pred_M027.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plots\n",
    "%matplotlib\n",
    "# all positions overview\n",
    "for name in k[11:12]:\n",
    "    model_name, loss_name, tdata, special, bs, _ = get_model_info(name)\n",
    "    f1 = plot_locaz_all(pred_R006[name],\n",
    "                        l=True,\n",
    "                        title='Model: {}{} | Loss: {} | Test-Data: {}'.format(model_name, special, loss_name, 'NFCHOA_R006'))\n",
    "    #f2 = plot_locaz_all(pred_M027[name],\n",
    "    #                    l=True,\n",
    "    #                    title='Model: {}{} | Loss: {} | Test-Data: {}'.format(model_name, special, loss_name, 'NFCHOA_M027'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# individual positions incl. gt comparison\n",
    "%matplotlib\n",
    "\n",
    "m_idx = 12\n",
    "pos_idx = 0\n",
    "\n",
    "#model_name, loss_name, tdata, special, bs, _ = get_model_info(k[m_idx])\n",
    "\n",
    "# manually wrap angles\n",
    "def wrap(a):\n",
    "    for i in range(len(a)):\n",
    "        if a[i] > 180:\n",
    "            a[i] = a[i]-360\n",
    "        elif a[i] < -180:\n",
    "            a[i] = a[i]+360\n",
    "    return a\n",
    "\n",
    "#title = 'Model: {}{} | Loss: {} | Test-Data: {}\\n Position: {}'.format(model_name, special, loss_name, 'NFCHOA_M027', pos_idx)\n",
    "f1, ax_p, ax_y = plot_locaz(wrap(pred_M027[k[m_idx]][pos_idx]), y_M027[k[m_idx]][pos_idx], l=True)\n",
    "#f.suptitle(title, fontsize='x-large')\n",
    "lines = (ax_p.get_children()[:1][0],ax_y.get_children()[:1][0],ax_p.get_children()[:][1],ax_p.get_children()[:][2],ax_p.get_children()[:][4])\n",
    "#f.legend(lines, ('predictions', 'human / gt', 'mean over subjects/repititions at 0° head rotation', '± 180°','± 180°'))\n",
    "\n",
    "#title = 'Model: {}{} | Loss: {} | Test-Data: {}\\n Position: {}'.format(model_name, special, loss_name, 'NFCHOA_R006', pos_idx)\n",
    "f2, ax_p, ax_y = plot_locaz(wrap(pred_R006[k[m_idx]][pos_idx]), y_R006[k[m_idx]][pos_idx], l=True)\n",
    "#f.suptitle(title, fontsize='x-large')\n",
    "lines = (ax_p.get_children()[:1][0],ax_y.get_children()[:1][0],ax_p.get_children()[:][1],ax_p.get_children()[:][2],ax_p.get_children()[:][4])\n",
    "#f.legend(lines, ('predictions', 'human / gt', 'mean over subjects/repititions at 0° head rotation', '± 180°','± 180°'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1.set_size_inches(10.5, 5)\n",
    "f1.savefig('f1.png', dpi=200)\n",
    "f2.set_size_inches(10.5, 5)\n",
    "f2.savefig('f2.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
